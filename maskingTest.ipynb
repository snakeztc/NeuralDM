{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from Utils.config import generalConfig, structDqnConfig, model_dir\n",
    "import numpy as np\n",
    "np.random.seed(generalConfig[\"global_seed\"])\n",
    "from keras.models import Graph\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Dropout, Activation, Masking\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.core import TimeDistributedMerge, TimeDistributedDense\n",
    "from keras.layers import containers\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle as pkl\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "usr_size = 10\n",
    "sys_size = 10\n",
    "sys_embed = 10\n",
    "usr_embed = 30\n",
    "embed_size = sys_embed + usr_embed + 1\n",
    "\n",
    "graph.add_input(name='usr', input_shape=(None, usr_size))\n",
    "graph.add_input(name='sys', input_shape=(None, sys_size))\n",
    "graph.add_input(name='cmp', input_shape=(None, 1))\n",
    "\n",
    "# add masking\n",
    "graph.add_node(Masking(mask_value=0.0, input_shape=(None, usr_size)), name=\"usr_mask\", input=\"usr\")\n",
    "graph.add_node(Masking(mask_value=0.0, input_shape=(None, sys_size)), name=\"sys_mask\", input=\"sys\")\n",
    "\n",
    "graph.add_node(TimeDistributedDense(sys_embed, input_dim=sys_size, init='he_normal'), name=\"sys_embed\", input=\"sys_mask\")\n",
    "graph.add_node(TimeDistributedDense(usr_embed, input_dim=usr_size), name=\"usr_embed\", input=\"usr_mask\")\n",
    "\n",
    "\n",
    "graph.add_node(Me(mask_value=0.0, input_shape=(None, embed_size)),\n",
    "               inputs=[\"sys_embed\", \"usr_embed\", \"cmp\"], name=\"turn_embed\", merge_mode='concat')\n",
    "\n",
    "loss = {}\n",
    "\n",
    "#shared_model.add(Masking(mask_value=0.0, input_shape=(None, embed_size)))\n",
    "shared_model = containers.Sequential()\n",
    "shared_model.add(LSTM(256, input_dim=embed_size, return_sequences=False))\n",
    "shared_model.add(Dropout(0.3))\n",
    "\n",
    "graph.add_node(shared_model, name=\"recurrent_layers\", input=\"turn_embed\")\n",
    "#graph.add_node(shared_model, name=\"recurrent_layers\", inputs=[\"sys_embed\", \"usr_embed\", \"cmp\"], merge_mode='concat')\n",
    "\n",
    "# policies\n",
    "policy_action_num = {\"verbal\":32, \"computer\": 3}\n",
    "\n",
    "for p_name in [\"verbal\", \"computer\"]:\n",
    "    graph.add_node(Dense(structDqnConfig[\"l1-\"+p_name], activation='tanh'), name=\"l1-\"+p_name, input=\"recurrent_layers\")\n",
    "    graph.add_node(Dropout(0.3), name=\"l1dp-\"+p_name, input=\"l1-\"+p_name)\n",
    "    graph.add_node(Dense(policy_action_num[p_name], activation='linear'), name=p_name, input='l1dp-'+p_name, create_output=True)\n",
    "    loss[p_name] = \"mse\"\n",
    "\n",
    "opt = RMSprop(clipvalue=1.0)\n",
    "graph.compile(optimizer=opt, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Layer (name)                  Output Shape                  Param #             \n",
      "--------------------------------------------------------------------------------\n",
      "Layer (usr)                   (None, None, 10)              0                   \n",
      "Layer (sys)                   (None, None, 10)              0                   \n",
      "Layer (cmp)                   (None, None, 1)               0                   \n",
      "Masking (usr_mask)            (None, None, 10)              0                   \n",
      "Masking (sys_mask)            (None, None, 10)              0                   \n",
      "TimeDistributedDense (sys_embe(None, None, 10)              110                 \n",
      "TimeDistributedDense (usr_embe(None, None, 30)              330                 \n",
      "Masking (turn_embed)          (None, None, 41)              0                   \n",
      "Sequential (recurrent_layers) (None, 256)                   305152              \n",
      "Dense (l1-verbal)             (None, 128)                   32896               \n",
      "Dropout (l1dp-verbal)         (None, 128)                   0                   \n",
      "Dense (verbal)                (None, 32)                    4128                \n",
      "Dense (l1-computer)           (None, 128)                   32896               \n",
      "Dropout (l1dp-computer)       (None, 128)                   0                   \n",
      "Dense (computer)              (None, 3)                     387                 \n",
      "Dense (verbal)                (None, 32)                    4128                \n",
      "Dense (computer)              (None, 3)                     387                 \n",
      "--------------------------------------------------------------------------------\n",
      "Total params: 375899\n",
      "--------------------------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make bias non-zero\n",
    "sys_w = graph.nodes[\"sys_embed\"].get_weights()\n",
    "sys_w[1] = np.zeros(sys_embed)\n",
    "graph.nodes[\"sys_embed\"].set_weights(sys_w)\n",
    "\n",
    "# user weights\n",
    "usr_w = graph.nodes[\"usr_embed\"].get_weights()\n",
    "usr_w[1] = np.zeros(usr_embed)\n",
    "graph.nodes[\"usr_embed\"].set_weights(usr_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "turn_embed_output = K.function([graph.inputs[i].input for i in graph.input_order],\n",
    "                              [graph.nodes['recurrent_layers'].get_output(train=False)])\n",
    "usr_embed_output = K.function([graph.inputs['usr'].input],\n",
    "                              [graph.nodes['usr_embed'].get_output_mask(train=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fake input\n",
    "sys = np.zeros((1, 5, sys_size))\n",
    "usr = np.zeros((1, 5, usr_size))\n",
    "com = np.zeros((1, 5, 1))\n",
    "sys[0, [2,3], :] = 1.0\n",
    "usr[0, [2,4], :] = 1.0\n",
    "com[0, [3], :] = 1.0\n",
    "\n",
    "input_dict = {'usr':usr, 'sys':sys, 'cmp':com}\n",
    "input_list = [usr, sys, com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': array([[-0.11927572,  0.20427363,  0.02865927]]), 'verbal': array([[ 0.00402713, -0.11726081,  0.07506087, -0.34203163,  0.11910778,\n",
      "         0.10639571, -0.04797643, -0.37948903,  0.17089853, -0.14354943,\n",
      "         0.07060702,  0.05614262,  0.11790424,  0.04424603,  0.08680534,\n",
      "        -0.0780632 , -0.18311547,  0.02878226,  0.11700052, -0.02067673,\n",
      "        -0.31823581,  0.2506201 ,  0.31887996,  0.19409446, -0.2112639 ,\n",
      "         0.10458054, -0.07540109,  0.31896442,  0.12354691, -0.06275554,\n",
      "         0.23527353,  0.08727904]])}\n"
     ]
    }
   ],
   "source": [
    "print graph.predict(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "output = turn_embed_output(input_list)[0]\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print usr_embed_output([usr])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
